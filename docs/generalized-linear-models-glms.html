<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 9 Generalized linear models (GLMs) | Exam PA Study Manual</title>
  <meta name="description" content=" 9 Generalized linear models (GLMs) | Exam PA Study Manual" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content=" 9 Generalized linear models (GLMs) | Exam PA Study Manual" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="sdcastillo/PA-R-Study-Manual" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 9 Generalized linear models (GLMs) | Exam PA Study Manual" />
  
  
  

<meta name="author" content="Sam Castillo" />


<meta name="date" content="2019-11-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/artificial_actuary_logo_favicon.png" type="image/x-icon" />
<link rel="prev" href="introduction-to-modeling.html"/>
<link rel="next" href="logistic-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Exam PA Study Manual</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What’s in this book</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#get-full-access-at-exampa.net"><i class="fa fa-check"></i><b>1.1</b> Get full access at <span>ExamPA.net</span></a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#content-samples"><i class="fa fa-check"></i><b>1.2</b> Content Samples</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#a-response-to-a-subscribers-question"><i class="fa fa-check"></i><b>1.2.1</b> A Response to a Subscriber’s Question</a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#an-original-practice-exam-project-statement"><i class="fa fa-check"></i><b>1.2.2</b> An Original Practice Exam Project Statement</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i><b>1.3</b> About the author</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#contribute"><i class="fa fa-check"></i><b>1.4</b> Contribute</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-exam.html"><a href="the-exam.html"><i class="fa fa-check"></i><b>2</b> The exam</a></li>
<li class="chapter" data-level="3" data-path="you-already-know-what-learning-is.html"><a href="you-already-know-what-learning-is.html"><i class="fa fa-check"></i><b>3</b> You already know what learning is</a></li>
<li class="chapter" data-level="4" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>4</b> Getting started</a><ul>
<li class="chapter" data-level="4.1" data-path="getting-started.html"><a href="getting-started.html#download-the-data"><i class="fa fa-check"></i><b>4.1</b> Download the data</a></li>
<li class="chapter" data-level="4.2" data-path="getting-started.html"><a href="getting-started.html#download-islr"><i class="fa fa-check"></i><b>4.2</b> Download ISLR</a></li>
<li class="chapter" data-level="4.3" data-path="getting-started.html"><a href="getting-started.html#new-users"><i class="fa fa-check"></i><b>4.3</b> New users</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-programming.html"><a href="r-programming.html"><i class="fa fa-check"></i><b>5</b> R programming</a><ul>
<li class="chapter" data-level="5.1" data-path="r-programming.html"><a href="r-programming.html#notebook-chunks"><i class="fa fa-check"></i><b>5.1</b> Notebook chunks</a></li>
<li class="chapter" data-level="5.2" data-path="r-programming.html"><a href="r-programming.html#basic-operations"><i class="fa fa-check"></i><b>5.2</b> Basic operations</a></li>
<li class="chapter" data-level="5.3" data-path="r-programming.html"><a href="r-programming.html#lists"><i class="fa fa-check"></i><b>5.3</b> Lists</a></li>
<li class="chapter" data-level="5.4" data-path="r-programming.html"><a href="r-programming.html#functions"><i class="fa fa-check"></i><b>5.4</b> Functions</a></li>
<li class="chapter" data-level="5.5" data-path="r-programming.html"><a href="r-programming.html#data-frames"><i class="fa fa-check"></i><b>5.5</b> Data frames</a></li>
<li class="chapter" data-level="5.6" data-path="r-programming.html"><a href="r-programming.html#pipes"><i class="fa fa-check"></i><b>5.6</b> Pipes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>6</b> Data manipulation</a><ul>
<li class="chapter" data-level="6.1" data-path="data-manipulation.html"><a href="data-manipulation.html#look-at-the-data"><i class="fa fa-check"></i><b>6.1</b> Look at the data</a></li>
<li class="chapter" data-level="6.2" data-path="data-manipulation.html"><a href="data-manipulation.html#transform-the-data"><i class="fa fa-check"></i><b>6.2</b> Transform the data</a></li>
<li class="chapter" data-level="6.3" data-path="data-manipulation.html"><a href="data-manipulation.html#exercises"><i class="fa fa-check"></i><b>6.3</b> Exercises</a></li>
<li class="chapter" data-level="6.4" data-path="data-manipulation.html"><a href="data-manipulation.html#answers-to-exercises"><i class="fa fa-check"></i><b>6.4</b> Answers to exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>7</b> Visualization</a><ul>
<li class="chapter" data-level="7.1" data-path="visualization.html"><a href="visualization.html#create-a-plot-object-ggplot"><i class="fa fa-check"></i><b>7.1</b> Create a plot object (ggplot)</a></li>
<li class="chapter" data-level="7.2" data-path="visualization.html"><a href="visualization.html#add-a-plot"><i class="fa fa-check"></i><b>7.2</b> Add a plot</a></li>
<li class="chapter" data-level="7.3" data-path="visualization.html"><a href="visualization.html#data-manipulation-chaining"><i class="fa fa-check"></i><b>7.3</b> Data manipulation chaining</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html"><i class="fa fa-check"></i><b>8</b> Introduction to Modeling</a><ul>
<li class="chapter" data-level="8.1" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#model-notation"><i class="fa fa-check"></i><b>8.1</b> Model Notation</a></li>
<li class="chapter" data-level="8.2" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>8.2</b> Ordinary least squares (OLS)</a></li>
<li class="chapter" data-level="8.3" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#example"><i class="fa fa-check"></i><b>8.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html"><i class="fa fa-check"></i><b>9</b> Generalized linear models (GLMs)</a><ul>
<li class="chapter" data-level="9.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>9.1</b> The <em>generalized</em> linear model</a></li>
<li class="chapter" data-level="9.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interpretation"><i class="fa fa-check"></i><b>9.2</b> Interpretation</a></li>
<li class="chapter" data-level="9.3" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#residuals"><i class="fa fa-check"></i><b>9.3</b> Residuals</a></li>
<li class="chapter" data-level="9.4" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#example-1"><i class="fa fa-check"></i><b>9.4</b> Example</a></li>
<li class="chapter" data-level="9.5" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#reference-levels"><i class="fa fa-check"></i><b>9.5</b> Reference levels</a></li>
<li class="chapter" data-level="9.6" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interactions"><i class="fa fa-check"></i><b>9.6</b> Interactions</a></li>
<li class="chapter" data-level="9.7" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#poisson-regression"><i class="fa fa-check"></i><b>9.7</b> Poisson Regression</a></li>
<li class="chapter" data-level="9.8" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#offsets"><i class="fa fa-check"></i><b>9.8</b> Offsets</a></li>
<li class="chapter" data-level="9.9" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#tweedie-regression"><i class="fa fa-check"></i><b>9.9</b> Tweedie regression</a></li>
<li class="chapter" data-level="9.10" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#stepwise-subset-selection"><i class="fa fa-check"></i><b>9.10</b> Stepwise subset selection</a></li>
<li class="chapter" data-level="9.11" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>9.11</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#model-form"><i class="fa fa-check"></i><b>10.1</b> Model form</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#example-2"><i class="fa fa-check"></i><b>10.2</b> Example</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#classification-metrics"><i class="fa fa-check"></i><b>10.3</b> Classification metrics</a><ul>
<li class="chapter" data-level="10.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#area-under-the-roc-curv-auc"><i class="fa fa-check"></i><b>10.3.1</b> Area Under the ROC Curv (AUC)</a></li>
<li class="chapter" data-level="10.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#additional-reading"><i class="fa fa-check"></i><b>10.3.2</b> Additional reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html"><i class="fa fa-check"></i><b>11</b> Penalized Linear Models</a><ul>
<li class="chapter" data-level="11.1" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#ridge-regression"><i class="fa fa-check"></i><b>11.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="11.2" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#lasso"><i class="fa fa-check"></i><b>11.2</b> Lasso</a></li>
<li class="chapter" data-level="11.3" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#elastic-net"><i class="fa fa-check"></i><b>11.3</b> Elastic Net</a></li>
<li class="chapter" data-level="11.4" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#advantages-and-disadvantages-1"><i class="fa fa-check"></i><b>11.4</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>12</b> Tree-based models</a><ul>
<li class="chapter" data-level="12.1" data-path="tree-based-models.html"><a href="tree-based-models.html#decision-trees"><i class="fa fa-check"></i><b>12.1</b> Decision Trees</a><ul>
<li class="chapter" data-level="12.1.1" data-path="tree-based-models.html"><a href="tree-based-models.html#model-form-1"><i class="fa fa-check"></i><b>12.1.1</b> Model form</a></li>
<li class="chapter" data-level="12.1.2" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-2"><i class="fa fa-check"></i><b>12.1.2</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="tree-based-models.html"><a href="tree-based-models.html#ensemble-learning"><i class="fa fa-check"></i><b>12.2</b> Ensemble learning</a><ul>
<li class="chapter" data-level="12.2.1" data-path="tree-based-models.html"><a href="tree-based-models.html#bagging"><i class="fa fa-check"></i><b>12.2.1</b> Bagging</a></li>
<li class="chapter" data-level="12.2.2" data-path="tree-based-models.html"><a href="tree-based-models.html#boosting"><i class="fa fa-check"></i><b>12.2.2</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="tree-based-models.html"><a href="tree-based-models.html#random-forests"><i class="fa fa-check"></i><b>12.3</b> Random Forests</a><ul>
<li class="chapter" data-level="12.3.1" data-path="tree-based-models.html"><a href="tree-based-models.html#model-form-2"><i class="fa fa-check"></i><b>12.3.1</b> Model form</a></li>
<li class="chapter" data-level="12.3.2" data-path="tree-based-models.html"><a href="tree-based-models.html#example-3"><i class="fa fa-check"></i><b>12.3.2</b> Example</a></li>
<li class="chapter" data-level="12.3.3" data-path="tree-based-models.html"><a href="tree-based-models.html#variable-importance"><i class="fa fa-check"></i><b>12.3.3</b> Variable Importance</a></li>
<li class="chapter" data-level="12.3.4" data-path="tree-based-models.html"><a href="tree-based-models.html#partial-dependence"><i class="fa fa-check"></i><b>12.3.4</b> Partial dependence</a></li>
<li class="chapter" data-level="12.3.5" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-3"><i class="fa fa-check"></i><b>12.3.5</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="tree-based-models.html"><a href="tree-based-models.html#gradient-boosted-trees"><i class="fa fa-check"></i><b>12.4</b> Gradient Boosted Trees</a><ul>
<li class="chapter" data-level="12.4.1" data-path="tree-based-models.html"><a href="tree-based-models.html#parameters"><i class="fa fa-check"></i><b>12.4.1</b> Parameters</a></li>
<li class="chapter" data-level="12.4.2" data-path="tree-based-models.html"><a href="tree-based-models.html#example-4"><i class="fa fa-check"></i><b>12.4.2</b> Example</a></li>
<li class="chapter" data-level="12.4.3" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-4"><i class="fa fa-check"></i><b>12.4.3</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="tree-based-models.html"><a href="tree-based-models.html#exercises-1"><i class="fa fa-check"></i><b>12.5</b> Exercises</a><ul>
<li class="chapter" data-level="12.5.1" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-with-randomforest"><i class="fa fa-check"></i><b>12.5.1</b> 1. RF with <code>randomForest</code></a></li>
<li class="chapter" data-level="12.5.2" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-tuning-with-caret"><i class="fa fa-check"></i><b>12.5.2</b> 2. RF tuning with <code>caret</code></a></li>
<li class="chapter" data-level="12.5.3" data-path="tree-based-models.html"><a href="tree-based-models.html#tuning-a-gbm-with-caret"><i class="fa fa-check"></i><b>12.5.3</b> 3. Tuning a GBM with <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="tree-based-models.html"><a href="tree-based-models.html#answers-to-exercises-1"><i class="fa fa-check"></i><b>12.6</b> Answers to Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="practice-exams.html"><a href="practice-exams.html"><i class="fa fa-check"></i><b>13</b> Practice Exams</a></li>
<li class="chapter" data-level="14" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Exam PA Study Manual</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generalized-linear-models-glms" class="section level1">
<h1><span class="header-section-number"> 9</span> Generalized linear models (GLMs)</h1>
<p>The linear model that we have considered up to this point, what we called “OLS”, assumes that the response is a linear combination of the predictor variables. For an error term <span class="math inline">\(\epsilon_i \sim N(0,\sigma^2)\)</span>, this is assumes that</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 X_1 + ... + \beta_p X_p + \epsilon
\]</span></p>
<p>Another way of saying this is that if <span class="math inline">\(X\)</span> is the matrix made up of columns <span class="math inline">\(X_1, ..., X_p\)</span>, then</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{X} \mathbf{\beta} + \mathbf{\epsilon}
\]</span></p>
<p>Another way of saying this is that “after we adjust for the data, the error is normally distributed and the variance is constant.” If <span class="math inline">\(I\)</span> is an n-by-in identity matrix, and <span class="math inline">\(\sigma^2 I\)</span> is the covariance matrix, then</p>
<p><span class="math display">\[
\mathbf{Y|X} \sim N( \mathbf{X \beta}, \mathbf{\sigma^2} I)
\]</span></p>
<hr />
<p>Because this notation is getting too cumbersome, we’re going to stop using bold letters to denote matrices and just use non-bold characters. From now on, <span class="math inline">\(\mathbf{X}\)</span> is the same as <span class="math inline">\(X\)</span>.</p>
<hr />
<p>These assumptions can be expressed in two parts:</p>
<ol style="list-style-type: decimal">
<li><p>A <em>random component</em>: The response variable <span class="math inline">\(Y|X\)</span> is normally distributed with mean <span class="math inline">\(\mu = \mu(X) = E(Y|X)\)</span></p></li>
<li><p>A link between the response and the covariates <span class="math inline">\(\mu(X) = X\beta\)</span></p></li>
</ol>
<div id="the-generalized-linear-model" class="section level2">
<h2><span class="header-section-number">9.1</span> The <em>generalized</em> linear model</h2>
<p>We relax these two assumptions by saying that the model is defined by</p>
<ol style="list-style-type: decimal">
<li><p>A random component: <span class="math inline">\(Y|X \sim \text{some exponential family distribution}\)</span></p></li>
<li><p>A <em>link function</em>: between the random component and <span class="math inline">\(X\)</span>: <span class="math inline">\(g(\mu(X)) = X\beta\)</span></p></li>
</ol>
<p>The possible combinations of link functions and distribution families are summarized nicely on <a href="https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function">Wikipedia</a>.</p>
<div class="figure"><span id="fig:unnamed-chunk-14"></span>
<img src="images/glm_links.png" alt="Distribution-Link Function Combinations" width="804" />
<p class="caption">
Figure 9.1: Distribution-Link Function Combinations
</p>
</div>
<p>For this exam, a common question is to ask candiates to choose the best distribution and link function. There is no all-encompasing answer, but a few suggestions are</p>
<ul>
<li>If <span class="math inline">\(Y\)</span> is counting something, such as the number of claims, number of accidents, or some other discrete and positive counting sequence, use the Poisson;</li>
<li>If <span class="math inline">\(Y\)</span> contains negative values, then do not use the Exponential, Gamma, or Inverse Gaussian as these are strictly positive. Conversely, if <span class="math inline">\(Y\)</span> is only positive, such as the price of a policy (price is always &gt; 0), or the claim costs, then these are good choices;</li>
<li>If <span class="math inline">\(Y\)</span> is binary, the the binomial response with either a Probit or Logit link. The Logit is more common.</li>
<li>If <span class="math inline">\(Y\)</span> has more than two categories, the multinomial distribution with either the Probit or Logic link (See Logistic Regression)</li>
</ul>
</div>
<div id="interpretation" class="section level2">
<h2><span class="header-section-number">9.2</span> Interpretation</h2>
<p>The exam will always ask you to interpret the GLM. These questions can usually be answered by inverting the link function and interpreting the coefficients. In the case of the log link, simply take the exponent of the coefficients and each of these represents a “relativity” factor.</p>
<p><span class="math display">\[
log(\mathbf{\hat{y}}) = \mathbf{X} \mathbf{\beta} \Rightarrow \mathbf{\hat{y}} = e^{\mathbf{X} \mathbf{\beta}}
\]</span></p>
<p>For a single observation <span class="math inline">\(y_i\)</span>, this is</p>
<p><span class="math display">\[
\text{exp}(\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_p x_{ip}) = \\
e^{\beta_0} e^{\beta_1 x_{i1}}e^{\beta_2 x_{i2}} ...  e^{\beta_p x_{ip}} = 
R_0 R_2 R_3 ... R_{p}
\]</span></p>
<p>Where <span class="math inline">\(R_k\)</span> is the <em>relativity</em> of the kth variable. This terminology is from insurance ratemaking, where actuaries need to be able to explain the impact of each variable in pricing insurance. The data science community does not use this language.</p>
<p>For binary outcomes with logit or probit link, there is no easy interpretation. This has come up in at least one past sample exam, and the solution was to create “psuedo” observations and observe how changing each <span class="math inline">\(x_k\)</span> would change the predicted value. Due to the time requirements, this is unlikely to come up on an exam. So if you are asked to use a logit or probit link, saying that the result is not easy to interpret should suffice.</p>
</div>
<div id="residuals" class="section level2">
<h2><span class="header-section-number">9.3</span> Residuals</h2>
<p>The word “residual” by itself actually means the “raw residual” in GLM language. This is the difference in actual vs. predicted values.</p>
<p><span class="math display">\[\text{Raw Residual} = y_i - \hat{y_i}\]</span></p>
<p>This are not meaningful for GLMs with non-Gaussian response families because the distribution changes depending on the response family chosen. To adjust for this, we need the concept of <em>deviance residual</em>.</p>
<p>To paraphrase from <a href="www.stats.ox.ac.uk/pub/bdr/IAUL/ModellingLecture5.pdf">this paper</a></p>
<p>Deviance is a way of assessing the adequacy of a model by comparing it with a more general
model with the maximum number of parameters that can be estimated. It is referred to
as the saturated model. In the saturated model there is basically one parameter per
observation. The deviance assesses the goodness of fit for the model by looking at the
difference between the log-likelihood functions of the saturated model and the model
under investigation, i.e. <span class="math inline">\(l(b_{sat},y) - l(b,y)\)</span>. Here sat <span class="math inline">\(b_{sat}\)</span> denotes the maximum likelihood
estimator of the parameter vector of the saturated model, <span class="math inline">\(\beta_{sat}\)</span> , and <span class="math inline">\(b\)</span> is the maximum
likelihood estimator of the parameters of the model under investigation, <span class="math inline">\(\beta\)</span>. The maximum likelihood estimator is the estimator that maximises the likelihood function. <strong>The deviance is defined as</strong></p>
<p><span class="math display">\[D = 2[l(b_{sat},y) - l(b,y)]\]</span>
The deviance residual uses the deviance of the ith observation <span class="math inline">\(d_i\)</span> and then takes the square root and applies the same sign (aka, the + or - part) of the raw residual.</p>
<p><span class="math display">\[\text{Deviance Residual} = \text{sign}(y_i - \hat{y_i})\sqrt{d_i}\]</span></p>
</div>
<div id="example-1" class="section level2">
<h2><span class="header-section-number">9.4</span> Example</h2>
<p>Just as with OLS, there is a <code>formula</code> and <code>data argument</code>. In addition, we need to specify the response distribution and link function.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" title="1">model =<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> charges <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>smoker, </a>
<a class="sourceLine" id="cb178-2" title="2">            <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>),</a>
<a class="sourceLine" id="cb178-3" title="3">            <span class="dt">data =</span> health_insurance)</a></code></pre></div>
<p>We see that <code>age</code>, <code>sex</code>, and <code>smoker</code> are all significant (p &lt;0.01). Reading off the coefficient signs, we see that claims</p>
<ul>
<li>Increase as age increases</li>
<li>Are higher for women</li>
<li>Are higher for smokers</li>
</ul>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb179-1" title="1">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</a></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)   7.82     0.0600     130.   0.       
## 2 age           0.0290   0.00134     21.6  3.40e- 89
## 3 sexmale      -0.0468   0.0377      -1.24 2.15e-  1
## 4 smokeryes     1.50     0.0467      32.1  3.25e-168</code></pre>
<p>Below you can see graph of deviance residuals vs. the predicted values.</p>
<p><strong>If this were a perfect model, all of these below assumptions would be met:</strong></p>
<ul>
<li>Scattered around zero?</li>
<li>Constant variance?</li>
<li>No obvious pattern?</li>
</ul>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb181-1" title="1"><span class="kw">plot</span>(model, <span class="dt">which =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="05-linear-models_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>The quantile-quantile (QQ) plot shows the quantiles of the deviance residuals (i.e., after adjusting for the Gamma distribution) against theoretical Gaussian quantiles.</p>
<p><strong>In a perfect model, all of these assumptions would be met:</strong></p>
<ul>
<li>Points lie on a straight line?<br />
</li>
<li>Tails are not significantly above or below line? Some tail deviation is ok.</li>
<li>No sudden “jumps”? This indicates many <span class="math inline">\(Y\)</span>’s which have the same value, such as insurance claims which all have the exact value of $100.00 or $0.00.</li>
</ul>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" title="1"><span class="kw">plot</span>(model, <span class="dt">which =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="05-linear-models_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div id="reference-levels" class="section level2">
<h2><span class="header-section-number">9.5</span> Reference levels</h2>
<p>When a categorical variable is used in a GLM, the model actually uses indicator variables for each level. The default reference level is the order of the R factors. For the <code>sex</code> variable, the order is <code>female</code> and then <code>male</code>. This means that the base level is <code>female</code> by default.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" title="1">health_insurance<span class="op">$</span>sex <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">levels</span>()</a></code></pre></div>
<pre><code>## [1] &quot;female&quot; &quot;male&quot;</code></pre>
<p>Why does this matter? Statistically, the coefficients are most stable when there are more observations.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" title="1">health_insurance<span class="op">$</span>sex <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a></code></pre></div>
<pre><code>## female   male 
##    662    676</code></pre>
<p>There is already a function to do this in the <code>tidyverse</code> called <code>fct_infreq</code>. Let’s quickly fix the <code>sex</code> column so that these factor levels are in order of frequency.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" title="1">health_insurance &lt;-<span class="st"> </span>health_insurance <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb187-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sex =</span> <span class="kw">fct_infreq</span>(sex))</a></code></pre></div>
<p>Now <code>male</code> is the base level.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb188-1" title="1">health_insurance<span class="op">$</span>sex <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">levels</span>()</a></code></pre></div>
<pre><code>## [1] &quot;male&quot;   &quot;female&quot;</code></pre>
</div>
<div id="interactions" class="section level2">
<h2><span class="header-section-number">9.6</span> Interactions</h2>
<p>An interaction occurs when the effect of a variable on the response is different depending on the level of other variables in the model.</p>
<p>Consider this model:</p>
<p>Let <span class="math inline">\(x_2\)</span> be an indicator variable, which is 1 for some records and 0 otherwise.</p>
<p><span class="math display">\[\hat{y_i} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2\]</span></p>
<p>There are now two different linear models dependong on whether <code>x_1</code> is 0 or 1.</p>
<p>When <span class="math inline">\(x_1 = 0\)</span>,</p>
<p><span class="math display">\[\hat{y_i} = \beta_0  + \beta_2 x_2\]</span></p>
<p>and when <span class="math inline">\(x_1 = 1\)</span></p>
<p><span class="math display">\[\hat{y_i} = \beta_0 + \beta_1 + \beta_2 x_2 + \beta_3 x_2\]</span>
By rewriting this we can see that the intercept changes from <span class="math inline">\(\beta_0\)</span> to <span class="math inline">\(\beta_0^*\)</span> and the slope changes from <span class="math inline">\(\beta_1\)</span> to <span class="math inline">\(\beta_1^*\)</span></p>
<p><span class="math display">\[
(\beta_0 + \beta_1) + (\beta_2 + \beta_3 ) x_2 \\
 = \beta_0^* + \beta_1^* x_2
\]</span></p>
<p>The SOA’s modules give an example with the using age and gender as below. This is not a very strong interaction, as the slopes are almost identical across <code>gender</code>.</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" title="1">interactions <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb190-2" title="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(age, actual, <span class="dt">color =</span> gender)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb190-3" title="3"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb190-4" title="4"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Age vs. Actual by Gender&quot;</span>, </a>
<a class="sourceLine" id="cb190-5" title="5">       <span class="dt">subtitle =</span> <span class="st">&quot;Interactions imply different slopes&quot;</span>,</a>
<a class="sourceLine" id="cb190-6" title="6">       <span class="dt">caption=</span> <span class="st">&quot;data: interactions&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-23"></span>
<img src="05-linear-models_files/figure-html/unnamed-chunk-23-1.png" alt="Example of weak interaction" width="672" />
<p class="caption">
Figure 9.2: Example of weak interaction
</p>
</div>
<p>Here is a clearer example from the <code>auto_claim</code> data. The lines show the slope of a linear model, assuming that only <code>BLUEBOOK</code> and <code>CAR_TYPE</code> were predictors in the model. You can see that the slope for Sedans and Sports Cars is higher than for Vans and Panel Trucks.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb191-1" title="1">auto_claim <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb191-2" title="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="kw">log</span>(CLM_AMT), <span class="kw">log</span>(BLUEBOOK), <span class="dt">color =</span> CAR_TYPE)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb191-3" title="3"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb191-4" title="4"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> F) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb191-5" title="5"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Kelly Bluebook Value vs Claim Amount&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-24"></span>
<img src="05-linear-models_files/figure-html/unnamed-chunk-24-1.png" alt="Example of strong interaction" width="672" />
<p class="caption">
Figure 9.3: Example of strong interaction
</p>
</div>
<p>Any time that the effect that one variable has on the response is different depending on the value of other variables we say that there is an interaction. We can also use an hypothesis test with a GLM to check this. Simply include an interaction term and see if the coefficient is zero at the desired significance level.</p>
</div>
<div id="poisson-regression" class="section level2">
<h2><span class="header-section-number">9.7</span> Poisson Regression</h2>
<p>When counting something, numbers can only be positive and increase by increments of 1. Statistically, the name for this is a Poisson Process, which is a model for a serious of discrete events where the average time between events is known, called the “rate” <span class="math inline">\(\lambda\)</span>, but the exact timing of events is unknown. We could just fit a single rate for all observations, but this would often be a simplification. For a time interval of length <span class="math inline">\(m\)</span>, the expected number of events is <span class="math inline">\(\lambda m\)</span>.</p>
<p>By using a GLM, we can fit a different rate for each observation. Because the response is a count, the appropriate response distribution is the Poisson.</p>
<p><span class="math display">\[Y_i|X_i \sim \text{Poisson}(\lambda_i m_i)\]</span></p>
<p>When all observations have the same exposure, <span class="math inline">\(m = 1\)</span>. When the mean of the data is far from the variance, an additional parameter known as the <em>dispersion parameter</em> is used. A classic example is when modeling insurance claim counts which have a lot of zero claims. Then the model is said to be an “over-dispersed Poisson” or “zero-inflated” model.</p>
</div>
<div id="offsets" class="section level2">
<h2><span class="header-section-number">9.8</span> Offsets</h2>
<p>In certain situations, it is convenient to include a constant term in the linear predictor. This is the same as including a variable that has a coefficient equal to 1. We call this an <em>offset</em>.</p>
<p><span class="math display">\[g(\mu) = \beta_0 + \beta_1 X_1 + ... + \beta_p X_p + \text{offset}\]</span></p>
</div>
<div id="tweedie-regression" class="section level2">
<h2><span class="header-section-number">9.9</span> Tweedie regression</h2>
<p>While this topic is briefly mentioned on the modules, the only R libraries which support Tweedie Regression (<code>statmod</code> and <code>tweedie</code>) are not on the syllabus, and so there is no way that the SOA could ask you to build a tweedie model. This means that you can be safely skip this section.</p>
</div>
<div id="stepwise-subset-selection" class="section level2">
<h2><span class="header-section-number">9.10</span> Stepwise subset selection</h2>
<p>In theory, we could test all possible combinations of variables and interaction terms. This includes all <span class="math inline">\(p\)</span> models with one predictor, all p-choose-2 models with two predictors, all p-choose-3 models with three predictors, and so forth. Then we take whichever model has the best performance as the final model.</p>
<p>This “brute force” approach is statistically ineffective: the more variables which are searched, the higher the chance of finding models that overfit.</p>
<p>A subtler method, known as <em>stepwise selection</em>, reduces the chances of overfitting by only looking at the most promising models.</p>
<p><strong>Forward Stepwise Selection:</strong></p>
<ol style="list-style-type: decimal">
<li>Start with no predictors in the model;</li>
<li>Evaluate all <span class="math inline">\(p\)</span> models which use only one predictor and choose the one with the best performance (highest <span class="math inline">\(R^2\)</span> or lowest <span class="math inline">\(\text{RSS}\)</span>);</li>
<li>Repeat the process when adding one additional predictor, and continue until there is a model with one predictor, a model with two predictors, a model with three predictors, and so forth until there are <span class="math inline">\(p\)</span> models;</li>
<li>Select the single best model which has the best <span class="math inline">\(\text{AIC}\)</span>,<span class="math inline">\(\text{BIC}\)</span>, or adjusted <span class="math inline">\(R^2\)</span>.</li>
</ol>
<p><strong>Backward Stepwise Selection:</strong></p>
<ol style="list-style-type: decimal">
<li>Start with a model that contains all predictors;</li>
<li>Create a model which removes all predictors;</li>
<li>Choose the best model which removes all-but-one predictor;</li>
<li>Choose the best model which removes all-but-two predictors;</li>
<li>Continue until there are <span class="math inline">\(p\)</span> models;</li>
<li>Select the single best model which has the best <span class="math inline">\(\text{AIC}\)</span>,<span class="math inline">\(\text{BIC}\)</span>, or adjusted <span class="math inline">\(R^2\)</span>.</li>
</ol>
<p><strong>Both Forward &amp; Backward Selection:</strong></p>
<p>A hybrid approach is to consider use both forward and backward selection. This is done by creating two lists of variables at each step, one from forward and one from backward selection. Then variables from <em>both</em> lists are tested to see if adding or subtracting from the current model would improve the fit or not. ISLR does not mention this directly, however, by default the <code>stepAIC</code> function uses a default of <code>both</code>.</p>
<blockquote>
<p><strong>Tip</strong>: Always load the <code>MASS</code> library before <code>dplyr</code> or <code>tidyverse</code>. Otherwise there will be conflicts as there are functions named <code>select()</code> and <code>filter()</code> in both. Alternatively, specify the library in the function call with <code>dplyr::select()</code>.</p>
</blockquote>
<table>
<thead>
<tr class="header">
<th>Readings</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://www.casact.org/pubs/monographs/papers/05-Goldburd-Khare-Tevet.pdf">CAS Monograph 5 Chapter 2</a></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="advantages-and-disadvantages" class="section level2">
<h2><span class="header-section-number">9.11</span> Advantages and disadvantages</h2>
<p>There is usually at least one question on the PA exam which asks you to “list some of the advantages and disadvantages of using this particular model”, and so here is one such list. It is unlikely that the grader will take off points for including too many comments and so a good strategy is to include everything that comes to mind.</p>
<p><strong>GLM Advantages</strong></p>
<ul>
<li>Easy to interpret</li>
<li>Can easily be deployed in spreadsheet format</li>
<li>Handles skewed data through different response distributions</li>
<li>Models the average response which leads to stable predictions on new data</li>
<li>Handles continuous and categorical data</li>
</ul>
<p><strong>GLM Disadvantages</strong></p>
<ul>
<li>Does not select features (without stepwise selection)</li>
<li>Strict assumptions around distribution shape, randomness of error terms, and variable correlations</li>
<li>Unable to detect non-linearity directly (although this can manually be addressed through feature engineering)</li>
<li>Sensitive to outliers</li>
<li>Low predictive power</li>
</ul>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-modeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sdcastillo/PA-R-Study-Manual/edit/master/05-linear-models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Exam-PA-Study-Manual.pdf", "Exam-PA-Study-Manual.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
