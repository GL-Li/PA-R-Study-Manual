<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 8 Introduction to Modeling | Exam PA Study Manual</title>
  <meta name="description" content=" 8 Introduction to Modeling | Exam PA Study Manual" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content=" 8 Introduction to Modeling | Exam PA Study Manual" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="sdcastillo/PA-R-Study-Manual" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 8 Introduction to Modeling | Exam PA Study Manual" />
  
  
  

<meta name="author" content="Sam Castillo" />


<meta name="date" content="2019-11-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/artificial_actuary_logo_favicon.png" type="image/x-icon" />
<link rel="prev" href="visualization.html"/>
<link rel="next" href="generalized-linear-models-glms.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Exam PA Study Manual</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What’s in this book</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#get-full-access"><i class="fa fa-check"></i><b>1.1</b> Get full access</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i><b>1.2</b> About the author</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#contribute"><i class="fa fa-check"></i><b>1.3</b> Contribute</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-exam.html"><a href="the-exam.html"><i class="fa fa-check"></i><b>2</b> The exam</a></li>
<li class="chapter" data-level="3" data-path="you-already-know-what-learning-is.html"><a href="you-already-know-what-learning-is.html"><i class="fa fa-check"></i><b>3</b> You already know what learning is</a></li>
<li class="chapter" data-level="4" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>4</b> Getting started</a><ul>
<li class="chapter" data-level="4.1" data-path="getting-started.html"><a href="getting-started.html#download-the-data"><i class="fa fa-check"></i><b>4.1</b> Download the data</a></li>
<li class="chapter" data-level="4.2" data-path="getting-started.html"><a href="getting-started.html#download-islr"><i class="fa fa-check"></i><b>4.2</b> Download ISLR</a></li>
<li class="chapter" data-level="4.3" data-path="getting-started.html"><a href="getting-started.html#new-users"><i class="fa fa-check"></i><b>4.3</b> New users</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-programming.html"><a href="r-programming.html"><i class="fa fa-check"></i><b>5</b> R programming</a><ul>
<li class="chapter" data-level="5.1" data-path="r-programming.html"><a href="r-programming.html#notebook-chunks"><i class="fa fa-check"></i><b>5.1</b> Notebook chunks</a></li>
<li class="chapter" data-level="5.2" data-path="r-programming.html"><a href="r-programming.html#basic-operations"><i class="fa fa-check"></i><b>5.2</b> Basic operations</a></li>
<li class="chapter" data-level="5.3" data-path="r-programming.html"><a href="r-programming.html#lists"><i class="fa fa-check"></i><b>5.3</b> Lists</a></li>
<li class="chapter" data-level="5.4" data-path="r-programming.html"><a href="r-programming.html#functions"><i class="fa fa-check"></i><b>5.4</b> Functions</a></li>
<li class="chapter" data-level="5.5" data-path="r-programming.html"><a href="r-programming.html#data-frames"><i class="fa fa-check"></i><b>5.5</b> Data frames</a></li>
<li class="chapter" data-level="5.6" data-path="r-programming.html"><a href="r-programming.html#pipes"><i class="fa fa-check"></i><b>5.6</b> Pipes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>6</b> Data manipulation</a><ul>
<li class="chapter" data-level="6.1" data-path="data-manipulation.html"><a href="data-manipulation.html#look-at-the-data"><i class="fa fa-check"></i><b>6.1</b> Look at the data</a></li>
<li class="chapter" data-level="6.2" data-path="data-manipulation.html"><a href="data-manipulation.html#transform-the-data"><i class="fa fa-check"></i><b>6.2</b> Transform the data</a></li>
<li class="chapter" data-level="6.3" data-path="data-manipulation.html"><a href="data-manipulation.html#exercises"><i class="fa fa-check"></i><b>6.3</b> Exercises</a></li>
<li class="chapter" data-level="6.4" data-path="data-manipulation.html"><a href="data-manipulation.html#answers-to-exercises"><i class="fa fa-check"></i><b>6.4</b> Answers to exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>7</b> Visualization</a><ul>
<li class="chapter" data-level="7.1" data-path="visualization.html"><a href="visualization.html#create-a-plot-object-ggplot"><i class="fa fa-check"></i><b>7.1</b> Create a plot object (ggplot)</a></li>
<li class="chapter" data-level="7.2" data-path="visualization.html"><a href="visualization.html#add-a-plot"><i class="fa fa-check"></i><b>7.2</b> Add a plot</a></li>
<li class="chapter" data-level="7.3" data-path="visualization.html"><a href="visualization.html#data-manipulation-chaining"><i class="fa fa-check"></i><b>7.3</b> Data manipulation chaining</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html"><i class="fa fa-check"></i><b>8</b> Introduction to Modeling</a><ul>
<li class="chapter" data-level="8.1" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#model-notation"><i class="fa fa-check"></i><b>8.1</b> Model Notation</a></li>
<li class="chapter" data-level="8.2" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>8.2</b> Ordinary least squares (OLS)</a></li>
<li class="chapter" data-level="8.3" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#example"><i class="fa fa-check"></i><b>8.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html"><i class="fa fa-check"></i><b>9</b> Generalized linear models (GLMs)</a><ul>
<li class="chapter" data-level="9.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>9.1</b> The <em>generalized</em> linear model</a></li>
<li class="chapter" data-level="9.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interpretation"><i class="fa fa-check"></i><b>9.2</b> Interpretation</a></li>
<li class="chapter" data-level="9.3" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#residuals"><i class="fa fa-check"></i><b>9.3</b> Residuals</a></li>
<li class="chapter" data-level="9.4" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#example-1"><i class="fa fa-check"></i><b>9.4</b> Example</a></li>
<li class="chapter" data-level="9.5" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#reference-levels"><i class="fa fa-check"></i><b>9.5</b> Reference levels</a></li>
<li class="chapter" data-level="9.6" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interactions"><i class="fa fa-check"></i><b>9.6</b> Interactions</a><ul>
<li class="chapter" data-level="9.6.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#poisson-regression"><i class="fa fa-check"></i><b>9.6.1</b> Poisson Regression</a></li>
<li class="chapter" data-level="9.6.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#tweedie-regression"><i class="fa fa-check"></i><b>9.6.2</b> Tweedie regression</a></li>
<li class="chapter" data-level="9.6.3" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#stepwise-subset-selection"><i class="fa fa-check"></i><b>9.6.3</b> Stepwise subset selection</a></li>
<li class="chapter" data-level="9.6.4" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>9.6.4</b> Advantages and disadvantages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#model-form"><i class="fa fa-check"></i><b>10.1</b> Model form</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#example-2"><i class="fa fa-check"></i><b>10.2</b> Example</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#classification-metrics"><i class="fa fa-check"></i><b>10.3</b> Classification metrics</a><ul>
<li class="chapter" data-level="10.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#area-under-the-roc-curv-auc"><i class="fa fa-check"></i><b>10.3.1</b> Area Under the ROC Curv (AUC)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html"><i class="fa fa-check"></i><b>11</b> Penalized Linear Models</a><ul>
<li class="chapter" data-level="11.1" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#ridge-regression"><i class="fa fa-check"></i><b>11.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="11.2" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#lasso"><i class="fa fa-check"></i><b>11.2</b> Lasso</a></li>
<li class="chapter" data-level="11.3" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#elastic-net"><i class="fa fa-check"></i><b>11.3</b> Elastic Net</a></li>
<li class="chapter" data-level="11.4" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#advantages-and-disadvantages-1"><i class="fa fa-check"></i><b>11.4</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>12</b> Tree-based models</a><ul>
<li class="chapter" data-level="12.1" data-path="tree-based-models.html"><a href="tree-based-models.html#decision-trees"><i class="fa fa-check"></i><b>12.1</b> Decision Trees</a><ul>
<li class="chapter" data-level="12.1.1" data-path="tree-based-models.html"><a href="tree-based-models.html#model-form-1"><i class="fa fa-check"></i><b>12.1.1</b> Model form</a></li>
<li class="chapter" data-level="12.1.2" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-2"><i class="fa fa-check"></i><b>12.1.2</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="tree-based-models.html"><a href="tree-based-models.html#ensemble-learning"><i class="fa fa-check"></i><b>12.2</b> Ensemble learning</a><ul>
<li class="chapter" data-level="12.2.1" data-path="tree-based-models.html"><a href="tree-based-models.html#bagging"><i class="fa fa-check"></i><b>12.2.1</b> Bagging</a></li>
<li class="chapter" data-level="12.2.2" data-path="tree-based-models.html"><a href="tree-based-models.html#boosting"><i class="fa fa-check"></i><b>12.2.2</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="tree-based-models.html"><a href="tree-based-models.html#random-forests"><i class="fa fa-check"></i><b>12.3</b> Random Forests</a><ul>
<li class="chapter" data-level="12.3.1" data-path="tree-based-models.html"><a href="tree-based-models.html#model-form-2"><i class="fa fa-check"></i><b>12.3.1</b> Model form</a></li>
<li class="chapter" data-level="12.3.2" data-path="tree-based-models.html"><a href="tree-based-models.html#example-3"><i class="fa fa-check"></i><b>12.3.2</b> Example</a></li>
<li class="chapter" data-level="12.3.3" data-path="tree-based-models.html"><a href="tree-based-models.html#variable-importance"><i class="fa fa-check"></i><b>12.3.3</b> Variable Importance</a></li>
<li class="chapter" data-level="12.3.4" data-path="tree-based-models.html"><a href="tree-based-models.html#partial-dependence"><i class="fa fa-check"></i><b>12.3.4</b> Partial dependence</a></li>
<li class="chapter" data-level="12.3.5" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-3"><i class="fa fa-check"></i><b>12.3.5</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="tree-based-models.html"><a href="tree-based-models.html#gradient-boosted-trees"><i class="fa fa-check"></i><b>12.4</b> Gradient Boosted Trees</a><ul>
<li class="chapter" data-level="12.4.1" data-path="tree-based-models.html"><a href="tree-based-models.html#parameters"><i class="fa fa-check"></i><b>12.4.1</b> Parameters</a></li>
<li class="chapter" data-level="12.4.2" data-path="tree-based-models.html"><a href="tree-based-models.html#example-4"><i class="fa fa-check"></i><b>12.4.2</b> Example</a></li>
<li class="chapter" data-level="12.4.3" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-4"><i class="fa fa-check"></i><b>12.4.3</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="tree-based-models.html"><a href="tree-based-models.html#exercises-1"><i class="fa fa-check"></i><b>12.5</b> Exercises</a><ul>
<li class="chapter" data-level="12.5.1" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-with-randomforest"><i class="fa fa-check"></i><b>12.5.1</b> 1. RF with <code>randomForest</code></a></li>
<li class="chapter" data-level="12.5.2" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-tuning-with-caret"><i class="fa fa-check"></i><b>12.5.2</b> 2. RF tuning with <code>caret</code></a></li>
<li class="chapter" data-level="12.5.3" data-path="tree-based-models.html"><a href="tree-based-models.html#tuning-a-gbm-with-caret"><i class="fa fa-check"></i><b>12.5.3</b> 3. Tuning a GBM with <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="tree-based-models.html"><a href="tree-based-models.html#answers-to-exercises-1"><i class="fa fa-check"></i><b>12.6</b> Answers to Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="practice-exams.html"><a href="practice-exams.html"><i class="fa fa-check"></i><b>13</b> Practice Exams</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Exam PA Study Manual</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-modeling" class="section level1">
<h1><span class="header-section-number"> 8</span> Introduction to Modeling</h1>
<p>About 40-50% of the exam grade is based on modeling.</p>
<div id="model-notation" class="section level2">
<h2><span class="header-section-number">8.1</span> Model Notation</h2>
<p>The number of observations will be denoted by <span class="math inline">\(n\)</span>. When we refer to the size of a data set, we are referring to <span class="math inline">\(n\)</span>. We use <span class="math inline">\(p\)</span> to refer the number of input variables used. The word “variables” is synonymous with “features”. For example, in the <code>health_insurance</code> data, the variables are <code>age</code>, <code>sex</code>, <code>bmi</code>, <code>children</code>, <code>smoker</code> and <code>region</code>. These 7 variables mean that <span class="math inline">\(p = 7\)</span>. The data is collected from 1,338 patients, which means that <span class="math inline">\(n = 1,338\)</span>.</p>
<p>Scalar numbers are denoted by ordinary variables (i.e., <span class="math inline">\(x = 2\)</span>, <span class="math inline">\(z = 4\)</span>), and vectors are denoted by bold-faced letters</p>
<p><span class="math display">\[\mathbf{a} = \begin{pmatrix} a_1 \\ a_2 \\ a_3 \end{pmatrix}\]</span></p>
<p>We use <span class="math inline">\(\mathbf{y}\)</span> to denote the target variable. This is the variable which we are trying to predict. This can be either a whole number, in which case we are performing <em>regression</em>, or a category, in which case we are performing <em>classification</em>. In the health insurance example, <code>y = charges</code>, which are the annual health care costs for a patient.</p>
<p>Both <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span> are important because they tell us what types of models are likely to work well, and which methods are likely to fail. For the PA exam, we will be dealing with small <span class="math inline">\(n\)</span> (&lt;100,000) due to the limitations of the Prometric computers. We will use a small <span class="math inline">\(p\)</span> (&lt; 20) in order to make the data sets easier to interpret.</p>
<p>We organize these variables into matrices. Take an example with <span class="math inline">\(p\)</span> = 2 columns and 3 observations. The matrix is said to be <span class="math inline">\(3 \times 2\)</span> (read as “2-by-3”) matrix.</p>
<p><span class="math display">\[
\mathbf{X} = \begin{pmatrix}x_{11} &amp; x_{21}\\
x_{21} &amp; x_{22}\\
x_{31} &amp; x_{32}
\end{pmatrix}
\]</span></p>
<p>The target is</p>
<p><span class="math display">\[\mathbf{Y} = \begin{pmatrix} y_1 \\ y_2 \\ y_3 \end{pmatrix}\]</span>
This represents the <em>unknown</em> quantity that we want to be able to predict. In the health care costs example, <span class="math inline">\(y_1\)</span> would be the costs of the first patient, <span class="math inline">\(y_2\)</span> the costs of the second patient, and so forth. The variables <span class="math inline">\(x_{11}\)</span> and <span class="math inline">\(x_{12}\)</span> might represent the first patient’s age and sex respectively, where <span class="math inline">\(x_{i1}\)</span> is the patient’s age, and <span class="math inline">\(x_{i2} = 1\)</span> if the ith patient is male and 0 if female.</p>
<p>Machine learning is about using <span class="math inline">\(\mathbf{X}\)</span> to predict <span class="math inline">\(\mathbf{y}\)</span>. We call this “y-hat”, or simply the prediction. This is based on a function of the data <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[\mathbf{\hat{Y}} = f(\mathbf{X}) = \begin{pmatrix} \hat{y_1} \\ \hat{y_2} \\ \hat{y_3} \end{pmatrix}\]</span></p>
<p>This is almost never going to happen perfectly, and so there is always an error term, <span class="math inline">\(\mathbf{\epsilon}\)</span>. This can be made smaller, but is never exactly zero.</p>
<p><span class="math display">\[
\mathbf{\hat{Y}} + \mathbf{\epsilon} = f(\mathbf{X}) + \mathbf{\epsilon}
\]</span></p>
<p>In other words, <span class="math inline">\(\epsilon = y - \hat{y}\)</span>. We call this the <em>residual</em>. When we predict a person’s health care costs, this is the difference between the predicted costs (which we had created the year before) and the actual costs that the patient experienced (of that current year).</p>
</div>
<div id="ordinary-least-squares-ols" class="section level2">
<h2><span class="header-section-number">8.2</span> Ordinary least squares (OLS)</h2>
<p>The type of model used refers to the class of function of <span class="math inline">\(f\)</span>. If <span class="math inline">\(f\)</span> is linear, then we are using a linear model. If <span class="math inline">\(f\)</span> is non-parametric (does not have input parameters), then it is non-parametric modeling. Linear models are linear in the parameters, <span class="math inline">\(\beta\)</span>.</p>
<p>We have the data <span class="math inline">\(\mathbf{X}\)</span> and the target <span class="math inline">\(\mathbf{y}\)</span>, where all of the y’s are real numbers, or <span class="math inline">\(y_i \in \mathbb{R}\)</span>.</p>
<p>We want to find a <span class="math inline">\(\mathbf{\beta}\)</span> so that</p>
<p><span class="math display">\[
\mathbf{\hat{Y}} = \mathbf{X} \mathbf{\beta}
\]</span></p>
<p>Which means that each <span class="math inline">\(y_i\)</span> is a linear combination of the variables <span class="math inline">\(x_1, ..., x_p\)</span>, plus a constant <span class="math inline">\(\beta_0\)</span> which is called the <em>intercept</em> term.</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_1 + ... + \beta_p x_p
\]</span></p>
<p>In the one-dimensional case, this creates a line connecting the points. In higher dimensions, this creates a hyperplane.</p>
<p><img src="05-linear-models_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>The question then is <strong>how can we choose the best values of</strong> <span class="math inline">\(\beta?\)</span> First of all, we need to define what we mean by “best”. Ideally, we will choose these values which will create close predictions of <span class="math inline">\(\mathbf{y}\)</span> on new, unseen data.<br />
To solve for <span class="math inline">\(\mathbf{\beta}\)</span>, we first need to define a <em>loss function</em>. This allows us to compare how well a model is fitting the data. The most commonly used loss function is the residual sum of squares (RSS), also called the <em>squared error loss</em> or the L2 norm. When RSS is small, then the predictions are close to the actual values and the model is a good fit. When RSS is large, the model is a poor fit.</p>
<p><span class="math display">\[
\text{RSS} = \sum_i(y_i - \hat{y})^2
\]</span></p>
<p>When you replace <span class="math inline">\(\hat{y_i}\)</span> in the above equation with <span class="math inline">\(\beta_0 + \beta_1 x_1 + ... + \beta_p x_p\)</span>, take the derivative with respect to <span class="math inline">\(\beta\)</span>, set equal to zero, and solve, we can find the optimal values. This turns the problem of statistics into a problem of numeric optimization, which computers can do quickly.</p>
<p>You might be asking: why does this need to be the squared error? Why not the absolute error, or the cubed error? Technically, these could be used as well. In fact, the absolute error (L1 norm) is useful in other models. Taking the square has a number of advantages.</p>
<ul>
<li>It provides the same solution if we assume that the distribution of <span class="math inline">\(\mathbf{Y}|\mathbf{X}\)</span> is guassian and maximize the likelihood function. This method is used for GLMs, in the next chapter.</li>
<li>Empirically it has been shown to be less likely to overfit as compared to other loss functions</li>
</ul>
</div>
<div id="example" class="section level2">
<h2><span class="header-section-number">8.3</span> Example</h2>
<p>In our health, we can create a linear model using <code>bmi</code>, <code>age</code>, and <code>sex</code> as an inputs.</p>
<p>The <code>formula</code> controls which variables are included. There are a few shortcuts for using R formulas.</p>
<table>
<colgroup>
<col width="43%" />
<col width="56%" />
</colgroup>
<thead>
<tr class="header">
<th>Formula</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>charges</code> ~ <code>bmi</code> + <code>age</code></td>
<td>Use <code>age</code> and <code>bmi</code> to predict <code>charges</code></td>
</tr>
<tr class="even">
<td><code>charges</code> ~ <code>bmi</code> + <code>age</code> + <code>bmi</code>*<code>age</code></td>
<td>Use <code>age</code>,<code>bmi</code> as well as an interaction to predict <code>charges</code></td>
</tr>
<tr class="odd">
<td><code>charges</code> ~ (<code>bmi &gt; 20</code>) + <code>age</code></td>
<td>Use an indicator variable for <code>bmi &gt; 20</code> <code>age</code> to predict <code>charges</code></td>
</tr>
<tr class="even">
<td>log(<code>charges</code>) ~ log(<code>bmi</code>) + log(<code>age</code>)</td>
<td>Use the logs of <code>age</code> and <code>bmi</code> to predict log(<code>charges</code>)</td>
</tr>
<tr class="odd">
<td><code>charges</code> ~ .</td>
<td>Use all variables to predict <code>charges</code></td>
</tr>
</tbody>
</table>
<p>You can use formulas to create new variables (aka feature engineering). This can save you from needing to re-run code to create data.</p>
<p>Below we fit a simple linear model to predict charges.</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb166-1" title="1"><span class="kw">library</span>(ExamPAData)</a>
<a class="sourceLine" id="cb166-2" title="2"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb166-3" title="3"></a>
<a class="sourceLine" id="cb166-4" title="4">model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> health_insurance, <span class="dt">formula =</span> charges <span class="op">~</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>age)</a></code></pre></div>
<p>The <code>summary</code> function gives details about the model. First, the <code>Estimate</code>, gives you the coefficients. The <code>Std. Error</code> is the error of the estimate for the coefficient. Higher standard error means greater uncertainty. This is relative to the average value of that variable. The <code>t value</code> tells you how “big” this error really is based on standard deviations. A larger <code>t value</code> implies a low probability of the null hypothesis being rejected saying that the coefficient is zero. This is the same as having a p-value (<code>Pr (&gt;|t|))</code>) being close to zero.</p>
<p>The little <code>*</code>, <code>**</code>, <code>***</code> indicate that the variable is either somewhat significant, significant, or highly significant. “significance” here means that there is a low probability of the coefficient being that size if there were <em>no actual casual relationship</em>, or if the data was random noise.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" title="1"><span class="kw">summary</span>(model)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = charges ~ bmi + age, data = health_insurance)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -14457  -7045  -5136   7211  48022 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -6424.80    1744.09  -3.684 0.000239 ***
## bmi           332.97      51.37   6.481 1.28e-10 ***
## age           241.93      22.30  10.850  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 11390 on 1335 degrees of freedom
## Multiple R-squared:  0.1172, Adjusted R-squared:  0.1159 
## F-statistic:  88.6 on 2 and 1335 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>When evaluating model performance, you should not rely on the <code>summary</code> alone as this is based on the training data. To look at performance, test the model on validation data. This can be done by a) using a hold out set, or b) using cross-validation, which is even better.</p>
<p>Let’s create an 80% training set and 20% testing set. You don’t need to worry about understanding this code as the exam will always give this to you.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" title="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb169-2" title="2"><span class="co">#create a train/test split</span></a>
<a class="sourceLine" id="cb169-3" title="3">index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> health_insurance<span class="op">$</span>charges, </a>
<a class="sourceLine" id="cb169-4" title="4">                             <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> F) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>()</a>
<a class="sourceLine" id="cb169-5" title="5">train &lt;-<span class="st">  </span>health_insurance <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(index)</a>
<a class="sourceLine" id="cb169-6" title="6">test &lt;-<span class="st"> </span>health_insurance <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>index)</a></code></pre></div>
<p>Train the model on the <code>train</code> and test on <code>test</code>.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" title="1">model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> train, <span class="dt">formula =</span> charges <span class="op">~</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>age)</a>
<a class="sourceLine" id="cb170-2" title="2">pred =<span class="st"> </span><span class="kw">predict</span>(model, test)</a></code></pre></div>
<p>Let’s look at the Root Mean Squared Error (RMSE).</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" title="1">get_rmse &lt;-<span class="st"> </span><span class="cf">function</span>(y, y_hat){</a>
<a class="sourceLine" id="cb171-2" title="2">  <span class="kw">sqrt</span>(<span class="kw">mean</span>((y <span class="op">-</span><span class="st"> </span>y_hat)<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb171-3" title="3">}</a>
<a class="sourceLine" id="cb171-4" title="4"></a>
<a class="sourceLine" id="cb171-5" title="5"><span class="kw">get_rmse</span>(pred, test<span class="op">$</span>charges)</a></code></pre></div>
<pre><code>## [1] 11285.3</code></pre>
<p>The above number does not tell us if this is a good model or not by itself. We need a comparison. The fastest check is to compare against a prediction of the mean. In other words, all values of the <code>y_hat</code> are the average of <code>charges</code></p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" title="1"><span class="kw">get_rmse</span>(<span class="kw">mean</span>(test<span class="op">$</span>charges), test<span class="op">$</span>charges)</a></code></pre></div>
<pre><code>## [1] 12243.43</code></pre>
<p>The RMSE is <strong>higher</strong> (worse) when using just the mean, which is what we expect. <strong>If you ever fit a model and get an error which is worse than the average prediction, something must be wrong.</strong></p>
<p>The next test is to see if any assumptions have been violated.</p>
<p>First, is there a pattern in the residuals? If there is, this means that the model is missing key information. For the model below, this is a <strong>yes</strong>, which means that this is a bad model. Because this is just for illustration, I’m going to continue using it, however.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" title="1"><span class="kw">plot</span>(model, <span class="dt">which =</span> <span class="dv">1</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<img src="05-linear-models_files/figure-html/unnamed-chunk-9-1.png" alt="Residuals vs. Fitted" width="672" />
<p class="caption">
Figure 8.1: Residuals vs. Fitted
</p>
</div>
<p>The normal QQ shows how well the quantiles of the predictions fit to a theoretical normal distribution. If this is true, then the graph is a straight 45-degree line. In this model, you can definitely see that this is not the case. If this were a good model, this distribution would be closer to normal.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb176-1" title="1"><span class="kw">plot</span>(model, <span class="dt">which =</span> <span class="dv">2</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-10"></span>
<img src="05-linear-models_files/figure-html/unnamed-chunk-10-1.png" alt="Normal Q-Q" width="672" />
<p class="caption">
Figure 8.2: Normal Q-Q
</p>
</div>
<p>Once you have chosen your model, you should re-train over the entire data set. This is to make the coefficients more stable because <code>n</code> is larger. Below you can see that the standard error is lower after training over the entire data set.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" title="1">all_data &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> health_insurance, </a>
<a class="sourceLine" id="cb177-2" title="2">               <span class="dt">formula =</span> charges <span class="op">~</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>age)</a>
<a class="sourceLine" id="cb177-3" title="3">testing &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> test, </a>
<a class="sourceLine" id="cb177-4" title="4">              <span class="dt">formula =</span> charges <span class="op">~</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>age)</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">full_data_std_error</th>
<th align="right">test_data_std_error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">1744.1</td>
<td align="right">3785.5</td>
</tr>
<tr class="even">
<td align="left">bmi</td>
<td align="right">51.4</td>
<td align="right">115.1</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">22.3</td>
<td align="right">49.1</td>
</tr>
</tbody>
</table>
<p>All interpretations should be based on the model which was trained on the entire data set. Obviously, this only makes a difference if you are interpreting the precise values of the coefficients. If you are just looking at which variables are included, or at the size and sign of the coefficients, then this would not change.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" title="1"><span class="kw">coefficients</span>(model)</a></code></pre></div>
<pre><code>## (Intercept)         bmi         age 
##  -6140.9619    340.8923    227.7131</code></pre>
<p>Translating the above into an equation we have</p>
<p><span class="math display">\[\hat{y_i} = -6,424.80 + 332.97 \space\text{bmi} + 241.93\space \text{age}\]</span></p>
<p>For example, if a patient has <code>bmi = 27.9</code> and <code>age = 19</code> then predicted value is</p>
<p><span class="math display">\[\hat{y_1} = -6,424.80 + (332.97)(27.9) + (241.93)(19) = 7,461.73\]</span></p>
<p>This model structure implies that each of the variables <span class="math inline">\(\mathbf{x_1}, ..., \mathbf{x_p}\)</span> each change the predicted <span class="math inline">\(\mathbf{\hat{y}}\)</span>. If <span class="math inline">\(x_{ij}\)</span> increases by one unit, then <span class="math inline">\(y_i\)</span> increases by <span class="math inline">\(\beta_j\)</span> units, regardless of what happens to all of the other variables. This is one of the main assumptions of linear models: <em>variable indepdendence</em>. If the variables are correlated, say, then this assumption will be violated.</p>
<table>
<thead>
<tr class="header">
<th>Readings</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ISLR 2.1 What is statistical learning?</td>
<td></td>
</tr>
<tr class="even">
<td>ISLR 2.2 Assessing model accuracy</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="visualization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="generalized-linear-models-glms.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sdcastillo/PA-R-Study-Manual/edit/master/05-linear-models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Exam-PA-Study-Manual.pdf", "Exam-PA-Study-Manual.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
