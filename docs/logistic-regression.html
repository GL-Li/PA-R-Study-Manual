<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 10 Logistic Regression | Exam PA Study Manual</title>
  <meta name="description" content=" 10 Logistic Regression | Exam PA Study Manual" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content=" 10 Logistic Regression | Exam PA Study Manual" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="sdcastillo/PA-R-Study-Manual" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 10 Logistic Regression | Exam PA Study Manual" />
  
  
  

<meta name="author" content="Sam Castillo" />


<meta name="date" content="2019-11-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/artificial_actuary_logo_favicon.png" type="image/x-icon" />
<link rel="prev" href="generalized-linear-models-glms.html"/>
<link rel="next" href="penalized-linear-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Exam PA Study Manual</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What’s in this book</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#get-full-access"><i class="fa fa-check"></i><b>1.1</b> Get full access</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i><b>1.2</b> About the author</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#help-to-make-this-book-even-better"><i class="fa fa-check"></i><b>1.3</b> Help to make this book even better</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-exam.html"><a href="the-exam.html"><i class="fa fa-check"></i><b>2</b> The exam</a></li>
<li class="chapter" data-level="3" data-path="you-already-know-what-learning-is.html"><a href="you-already-know-what-learning-is.html"><i class="fa fa-check"></i><b>3</b> You already know what learning is</a></li>
<li class="chapter" data-level="4" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>4</b> Getting started</a><ul>
<li class="chapter" data-level="4.1" data-path="getting-started.html"><a href="getting-started.html#download-the-data"><i class="fa fa-check"></i><b>4.1</b> Download the data</a></li>
<li class="chapter" data-level="4.2" data-path="getting-started.html"><a href="getting-started.html#download-islr"><i class="fa fa-check"></i><b>4.2</b> Download ISLR</a></li>
<li class="chapter" data-level="4.3" data-path="getting-started.html"><a href="getting-started.html#new-users"><i class="fa fa-check"></i><b>4.3</b> New users</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-programming.html"><a href="r-programming.html"><i class="fa fa-check"></i><b>5</b> R programming</a><ul>
<li class="chapter" data-level="5.1" data-path="r-programming.html"><a href="r-programming.html#notebook-chunks"><i class="fa fa-check"></i><b>5.1</b> Notebook chunks</a></li>
<li class="chapter" data-level="5.2" data-path="r-programming.html"><a href="r-programming.html#basic-operations"><i class="fa fa-check"></i><b>5.2</b> Basic operations</a></li>
<li class="chapter" data-level="5.3" data-path="r-programming.html"><a href="r-programming.html#lists"><i class="fa fa-check"></i><b>5.3</b> Lists</a></li>
<li class="chapter" data-level="5.4" data-path="r-programming.html"><a href="r-programming.html#functions"><i class="fa fa-check"></i><b>5.4</b> Functions</a></li>
<li class="chapter" data-level="5.5" data-path="r-programming.html"><a href="r-programming.html#data-frames"><i class="fa fa-check"></i><b>5.5</b> Data frames</a></li>
<li class="chapter" data-level="5.6" data-path="r-programming.html"><a href="r-programming.html#pipes"><i class="fa fa-check"></i><b>5.6</b> Pipes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>6</b> Data manipulation</a><ul>
<li class="chapter" data-level="6.1" data-path="data-manipulation.html"><a href="data-manipulation.html#look-at-the-data"><i class="fa fa-check"></i><b>6.1</b> Look at the data</a></li>
<li class="chapter" data-level="6.2" data-path="data-manipulation.html"><a href="data-manipulation.html#transform-the-data"><i class="fa fa-check"></i><b>6.2</b> Transform the data</a></li>
<li class="chapter" data-level="6.3" data-path="data-manipulation.html"><a href="data-manipulation.html#exercises"><i class="fa fa-check"></i><b>6.3</b> Exercises</a></li>
<li class="chapter" data-level="6.4" data-path="data-manipulation.html"><a href="data-manipulation.html#answers-to-exercises"><i class="fa fa-check"></i><b>6.4</b> Answers to exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>7</b> Visualization</a><ul>
<li class="chapter" data-level="7.1" data-path="visualization.html"><a href="visualization.html#create-a-plot-object-ggplot"><i class="fa fa-check"></i><b>7.1</b> Create a plot object (ggplot)</a></li>
<li class="chapter" data-level="7.2" data-path="visualization.html"><a href="visualization.html#add-a-plot"><i class="fa fa-check"></i><b>7.2</b> Add a plot</a></li>
<li class="chapter" data-level="7.3" data-path="visualization.html"><a href="visualization.html#data-manipulation-chaining"><i class="fa fa-check"></i><b>7.3</b> Data manipulation chaining</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html"><i class="fa fa-check"></i><b>8</b> Introduction to Modeling</a><ul>
<li class="chapter" data-level="8.1" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#model-notation"><i class="fa fa-check"></i><b>8.1</b> Model Notation</a></li>
<li class="chapter" data-level="8.2" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>8.2</b> Ordinary least squares (OLS)</a></li>
<li class="chapter" data-level="8.3" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#example"><i class="fa fa-check"></i><b>8.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html"><i class="fa fa-check"></i><b>9</b> Generalized linear models (GLMs)</a><ul>
<li class="chapter" data-level="9.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#model-form"><i class="fa fa-check"></i><b>9.1</b> Model form</a></li>
<li class="chapter" data-level="9.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interpretation"><i class="fa fa-check"></i><b>9.2</b> Interpretation</a></li>
<li class="chapter" data-level="9.3" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#residuals"><i class="fa fa-check"></i><b>9.3</b> Residuals</a></li>
<li class="chapter" data-level="9.4" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#example-1"><i class="fa fa-check"></i><b>9.4</b> Example</a></li>
<li class="chapter" data-level="9.5" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#reference-levels"><i class="fa fa-check"></i><b>9.5</b> Reference levels</a></li>
<li class="chapter" data-level="9.6" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interactions"><i class="fa fa-check"></i><b>9.6</b> Interactions</a><ul>
<li class="chapter" data-level="9.6.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#poisson-regression"><i class="fa fa-check"></i><b>9.6.1</b> Poisson Regression</a></li>
<li class="chapter" data-level="9.6.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#tweedie-regression"><i class="fa fa-check"></i><b>9.6.2</b> Tweedie regression</a></li>
<li class="chapter" data-level="9.6.3" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#stepwise-subset-selection"><i class="fa fa-check"></i><b>9.6.3</b> Stepwise subset selection</a></li>
<li class="chapter" data-level="9.6.4" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>9.6.4</b> Advantages and disadvantages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#model-form-1"><i class="fa fa-check"></i><b>10.1</b> Model form</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#example-2"><i class="fa fa-check"></i><b>10.2</b> Example</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#classification-metrics"><i class="fa fa-check"></i><b>10.3</b> Classification metrics</a><ul>
<li class="chapter" data-level="10.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#area-under-the-roc-curv-auc"><i class="fa fa-check"></i><b>10.3.1</b> Area Under the ROC Curv (AUC)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html"><i class="fa fa-check"></i><b>11</b> Penalized Linear Models</a><ul>
<li class="chapter" data-level="11.1" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#ridge-regression"><i class="fa fa-check"></i><b>11.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="11.2" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#lasso"><i class="fa fa-check"></i><b>11.2</b> Lasso</a></li>
<li class="chapter" data-level="11.3" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#elastic-net"><i class="fa fa-check"></i><b>11.3</b> Elastic Net</a></li>
<li class="chapter" data-level="11.4" data-path="penalized-linear-models.html"><a href="penalized-linear-models.html#advantages-and-disadvantages-1"><i class="fa fa-check"></i><b>11.4</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>12</b> Tree-based models</a><ul>
<li class="chapter" data-level="12.1" data-path="tree-based-models.html"><a href="tree-based-models.html#decision-trees"><i class="fa fa-check"></i><b>12.1</b> Decision Trees</a><ul>
<li class="chapter" data-level="12.1.1" data-path="tree-based-models.html"><a href="tree-based-models.html#model-form-2"><i class="fa fa-check"></i><b>12.1.1</b> Model form</a></li>
<li class="chapter" data-level="12.1.2" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-2"><i class="fa fa-check"></i><b>12.1.2</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="tree-based-models.html"><a href="tree-based-models.html#ensemble-learning"><i class="fa fa-check"></i><b>12.2</b> Ensemble learning</a><ul>
<li class="chapter" data-level="12.2.1" data-path="tree-based-models.html"><a href="tree-based-models.html#bagging"><i class="fa fa-check"></i><b>12.2.1</b> Bagging</a></li>
<li class="chapter" data-level="12.2.2" data-path="tree-based-models.html"><a href="tree-based-models.html#boosting"><i class="fa fa-check"></i><b>12.2.2</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="tree-based-models.html"><a href="tree-based-models.html#random-forests"><i class="fa fa-check"></i><b>12.3</b> Random Forests</a><ul>
<li class="chapter" data-level="12.3.1" data-path="tree-based-models.html"><a href="tree-based-models.html#model-form-3"><i class="fa fa-check"></i><b>12.3.1</b> Model form</a></li>
<li class="chapter" data-level="12.3.2" data-path="tree-based-models.html"><a href="tree-based-models.html#example-3"><i class="fa fa-check"></i><b>12.3.2</b> Example</a></li>
<li class="chapter" data-level="12.3.3" data-path="tree-based-models.html"><a href="tree-based-models.html#variable-importance"><i class="fa fa-check"></i><b>12.3.3</b> Variable Importance</a></li>
<li class="chapter" data-level="12.3.4" data-path="tree-based-models.html"><a href="tree-based-models.html#partial-dependence"><i class="fa fa-check"></i><b>12.3.4</b> Partial dependence</a></li>
<li class="chapter" data-level="12.3.5" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-3"><i class="fa fa-check"></i><b>12.3.5</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="tree-based-models.html"><a href="tree-based-models.html#gradient-boosted-trees"><i class="fa fa-check"></i><b>12.4</b> Gradient Boosted Trees</a><ul>
<li class="chapter" data-level="12.4.1" data-path="tree-based-models.html"><a href="tree-based-models.html#parameters"><i class="fa fa-check"></i><b>12.4.1</b> Parameters</a></li>
<li class="chapter" data-level="12.4.2" data-path="tree-based-models.html"><a href="tree-based-models.html#example-4"><i class="fa fa-check"></i><b>12.4.2</b> Example</a></li>
<li class="chapter" data-level="12.4.3" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-4"><i class="fa fa-check"></i><b>12.4.3</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="tree-based-models.html"><a href="tree-based-models.html#exercises-1"><i class="fa fa-check"></i><b>12.5</b> Exercises</a></li>
<li class="chapter" data-level="12.6" data-path="tree-based-models.html"><a href="tree-based-models.html#answers-to-exercises-1"><i class="fa fa-check"></i><b>12.6</b> Answers to Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="practice-exams.html"><a href="practice-exams.html"><i class="fa fa-check"></i><b>13</b> Practice Exams</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Exam PA Study Manual</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level1">
<h1><span class="header-section-number"> 10</span> Logistic Regression</h1>
<div id="model-form-1" class="section level2">
<h2><span class="header-section-number">10.1</span> Model form</h2>
<p>Logistic regression is a special type of GLM. The name is confusing because the objective is <em>classification</em> and not regression. While most examples focus on binary classification, logistic regression also works for multiclass classification.</p>
<p>The model form is as before</p>
<p><span class="math display">\[g(\mathbf{\hat{y}}) = \mathbf{X} \mathbf{\beta}\]</span></p>
<p>However, now the target <span class="math inline">\(y_i\)</span> is a category. Our objective is to predict a probability of being in each category. For regression, <span class="math inline">\(\hat{y_i}\)</span> can be any number, but now we need <span class="math inline">\(0 \leq \hat{y_i} \leq 1\)</span>.</p>
<p>We can use a special link function, known as the <em>standard logistic function</em>, <em>sigmoid</em>, or <em>logit</em>, to force the output to be in this range of <span class="math inline">\(\{0,1\}\)</span>.</p>
<p><span class="math display">\[\mathbf{\hat{y}} = g^{-1}(\mathbf{X} \mathbf{\beta}) = \frac{1}{1 + e^{-\mathbf{X} \mathbf{\beta}}}\]</span></p>
<div class="figure"><span id="fig:unnamed-chunk-27"></span>
<img src="05-linear-models_files/figure-html/unnamed-chunk-27-1.png" alt="Standard Logistic Function" width="384" />
<p class="caption">
Figure 10.1: Standard Logistic Function
</p>
</div>
<p>Other link functions for classification problems are possible as well, although the logistic function is the most common. If a problem asks for an alternative link, such as the <em>probit</em>, fit both models and compare the performance.</p>
</div>
<div id="example-2" class="section level2">
<h2><span class="header-section-number">10.2</span> Example</h2>
<p>Using the <code>auto_claim</code> data, we predict whether or not a policy has a claim. This is also known as the <em>claim frequency</em>.</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb195-1" title="1">auto_claim <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(CLM_FLAG)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   CLM_FLAG     n
##   &lt;chr&gt;    &lt;int&gt;
## 1 No        7556
## 2 Yes       2740</code></pre>
<p>About 40% do not have a claim while 60% have at least one claim.</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" title="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb197-2" title="2">index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> auto_claim<span class="op">$</span>CLM_FLAG, </a>
<a class="sourceLine" id="cb197-3" title="3">                             <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> F) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>()</a>
<a class="sourceLine" id="cb197-4" title="4">auto_claim &lt;-<span class="st"> </span>auto_claim <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb197-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">target =</span> <span class="kw">as.factor</span>(<span class="kw">ifelse</span>(CLM_FLAG <span class="op">==</span><span class="st"> &quot;Yes&quot;</span>, <span class="dv">1</span>,<span class="dv">0</span>)))</a>
<a class="sourceLine" id="cb197-6" title="6">train &lt;-<span class="st">  </span>auto_claim <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(index)</a>
<a class="sourceLine" id="cb197-7" title="7">test &lt;-<span class="st"> </span>auto_claim <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>index)</a>
<a class="sourceLine" id="cb197-8" title="8"></a>
<a class="sourceLine" id="cb197-9" title="9">frequency &lt;-<span class="st"> </span><span class="kw">glm</span>(target <span class="op">~</span><span class="st"> </span>AGE <span class="op">+</span><span class="st"> </span>GENDER <span class="op">+</span><span class="st"> </span>MARRIED <span class="op">+</span><span class="st"> </span>CAR_USE <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb197-10" title="10"><span class="st">                   </span>BLUEBOOK <span class="op">+</span><span class="st"> </span>CAR_TYPE <span class="op">+</span><span class="st"> </span>AREA, </a>
<a class="sourceLine" id="cb197-11" title="11">                 <span class="dt">data=</span>train, </a>
<a class="sourceLine" id="cb197-12" title="12">                 <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">&quot;logit&quot;</span>))</a></code></pre></div>
<p>All of the variables except for the <code>CAR_TYPE</code> are highly significant. The car types <code>SPORTS CAR</code> and <code>SUV</code> appear to be significant, and so if we wanted to make the model simpler we could create indicator variables for <code>CAR_TYPE == SPORTS CAR</code> and <code>CAR_TYPE == SUV</code>.</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" title="1">frequency <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = target ~ AGE + GENDER + MARRIED + CAR_USE + BLUEBOOK + 
##     CAR_TYPE + AREA, family = binomial(link = &quot;logit&quot;), data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8431  -0.8077  -0.5331   0.9575   3.0441  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)        -3.523e-01  2.517e-01  -1.400  0.16160    
## AGE                -2.289e-02  3.223e-03  -7.102 1.23e-12 ***
## GENDERM            -1.124e-02  9.304e-02  -0.121  0.90383    
## MARRIEDYes         -6.028e-01  5.445e-02 -11.071  &lt; 2e-16 ***
## CAR_USEPrivate     -1.008e+00  6.569e-02 -15.350  &lt; 2e-16 ***
## BLUEBOOK           -4.025e-05  4.699e-06  -8.564  &lt; 2e-16 ***
## CAR_TYPEPickup     -6.687e-02  1.390e-01  -0.481  0.63048    
## CAR_TYPESedan      -3.689e-01  1.383e-01  -2.667  0.00765 ** 
## CAR_TYPESports Car  6.159e-01  1.891e-01   3.256  0.00113 ** 
## CAR_TYPESUV         2.982e-01  1.772e-01   1.683  0.09240 .  
## CAR_TYPEVan        -8.983e-03  1.319e-01  -0.068  0.94569    
## AREAUrban           2.128e+00  1.064e-01  19.993  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 9544.3  on 8236  degrees of freedom
## Residual deviance: 8309.6  on 8225  degrees of freedom
## AIC: 8333.6
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>There is no easy way of interpreting the coefficients when using a logit link function. The most inference that we can make is to note which variables are significant.</p>
<ul>
<li><code>CAR_USE</code>, <code>MARRIED</code>, <code>BLUEBOOK</code> are highly significant</li>
<li>Certain values of <code>CAR_TYPE</code> are significant but others are not.</li>
</ul>
<p>The output is a predicted probability. We can see that this is centered around a probability of about 0.5.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" title="1">preds &lt;-<span class="st"> </span><span class="kw">predict</span>(frequency, <span class="dt">newdat=</span>test,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb200-2" title="2"><span class="kw">qplot</span>(preds) </a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-31"></span>
<img src="05-linear-models_files/figure-html/unnamed-chunk-31-1.png" alt="Distribution of Predicted Probability" width="480" />
<p class="caption">
Figure 10.2: Distribution of Predicted Probability
</p>
</div>
<p>In order to convert these values to predicted 0’s and 1’s, we assign a <em>cutoff</em> value so that if <span class="math inline">\(\hat{y}\)</span> is above this threshold we use a 1 and 0 othersise. The default cutoff is 0.5. We change this to 0.3 and see that there are 763 policies predicted to have claims.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" title="1">test &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">pred_zero_one =</span> <span class="kw">as.factor</span>(<span class="dv">1</span><span class="op">*</span>(preds<span class="op">&gt;</span>.<span class="dv">3</span>)))</a>
<a class="sourceLine" id="cb201-2" title="2"><span class="kw">summary</span>(test<span class="op">$</span>pred_zero_one)</a></code></pre></div>
<pre><code>##    0    1 
## 1296  763</code></pre>
<p>How do we decide on this cutoff value? We need to compare cutoff values based on some evaluation metric. For example, we can use <em>accuracy</em>.</p>
<p><span class="math display">\[\text{Accuracy} = \frac{\text{Correct Guesses}}{\text{Total Guesses}}\]</span></p>
<p>This results in an accuracy of 70%. But is this good?</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb203-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.699</code></pre>
<p>Consider what would happen if we just predicted all 0’s. The accuracy is 74%.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(<span class="dv">0</span> <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.734</code></pre>
<p>For policies which experience claims the accuracy is 63%.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb207-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb207-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb207-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.631</code></pre>
<p>But for policies that don’t actually experience claims this is 72%.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb209-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.724</code></pre>
<p>How do we know if this is a good model? We can repeat this process with a different cutoff value and get different accuracy metrics for these groups. Let’s use a cutoff of 0.6.</p>
<p>75%</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb211-1" title="1">test &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">pred_zero_one =</span> <span class="kw">as.factor</span>(<span class="dv">1</span><span class="op">*</span>(preds<span class="op">&gt;</span>.<span class="dv">6</span>)))</a>
<a class="sourceLine" id="cb211-2" title="2">test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.752</code></pre>
<p>10% for policies with claims and 98% for policies without claims.</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb213-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb213-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb213-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.108</code></pre>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb215-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb215-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb215-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.985</code></pre>
<p>The punchline is that the accuracy depends on the cutoff value, and changing the cutoff value changes whether the model is accuracy for the positive classes (policies with actual claims) vs. the negative classes (policies without claims).</p>
</div>
<div id="classification-metrics" class="section level2">
<h2><span class="header-section-number">10.3</span> Classification metrics</h2>
<p>For regression problems, when the output is a whole number, we can use the sum of squares <span class="math inline">\(\text{RSS}\)</span>, the r-squared <span class="math inline">\(R^2\)</span>, the mean absolute error <span class="math inline">\(\text{MAE}\)</span>, and the likelihood. For classification problems where the output is in <span class="math inline">\(\{0,1\}\)</span>, we need to a new set of metrics.</p>
<p>A <em>confusion matrix</em> shows is a table that summarises how the model classifies each group.</p>
<ul>
<li>No claims and predicted to not have claims - <strong>True Negatives (TN) = 1,489</strong></li>
<li>Had claims and predicted to have claims - <strong>True Positives (TP) = 59</strong></li>
<li>No claims but predited to have claims - <strong>False Negatives (FN) = 22</strong></li>
<li>Had claims but predicted not to - <strong>False Positives (FP) = 489</strong></li>
</ul>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb217-1" title="1"><span class="kw">confusionMatrix</span>(test<span class="op">$</span>pred_zero_one,<span class="kw">factor</span>(test<span class="op">$</span>target))<span class="op">$</span>table</a></code></pre></div>
<pre><code>##           Reference
## Prediction    0    1
##          0 1489  489
##          1   22   59</code></pre>
<p>These definitions allow us to measure performance on the different groups.</p>
<p><em>Precision</em> answers the question “out of all of the positive predictions, what percentage were correct?”</p>
<p><span class="math display">\[\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}\]</span></p>
<p><em>Recall</em> answers the question “out of all of positive examples in the data set, what percentage were correct?”</p>
<p><span class="math display">\[\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\]</span></p>
<p>The choice of using precision or recall depends on the relative cost of making a FP or a FN error. If FP errors are expensive, then use precision; if FN errors are expensive, then use recall.</p>
<p><strong>Example A:</strong> the model trying to detect a deadly disease, which only 1 out of every 1000 patient’s survive without early detection. Then the goal should be to optimize <em>recall</em>, because we would want every patient that has the disease to get detected.</p>
<p><strong>Example B:</strong> the model is detecting which emails are spam or not. If an important email is flagged as spam incorrectly, the cost is 5 hours of lost productivity. In this case, <em>precision</em> is the main concern.</p>
<p>In some cases we can compare this “cost” in actual values. For example, if a federal court is predicting if a criminal will recommit or not, they can agree that “1 out of every 20 guilty individuals going free” in exchange for “90% of those who are guilty being convicted”. When money is involed, this a dollar amount can be used: flagging non-spam as spam may cost $100 whereas missing a spam email may cost $2. Then the cost-weighted accuracy is</p>
<p><span class="math display">\[\text{Cost} = (100)(\text{FN}) + (2)(\text{FP})\]</span></p>
<p>Then the cutoff value can be tuned in order to find the minimum cost.</p>
<p>Fortunately, all of this is handled in a single function called <code>confusionMatrix</code>.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb219-1" title="1"><span class="kw">confusionMatrix</span>(test<span class="op">$</span>pred_zero_one,<span class="kw">factor</span>(test<span class="op">$</span>target))</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1489  489
##          1   22   59
##                                           
##                Accuracy : 0.7518          
##                  95% CI : (0.7326, 0.7704)
##     No Information Rate : 0.7339          
##     P-Value [Acc &gt; NIR] : 0.03366         
##                                           
##                   Kappa : 0.1278          
##                                           
##  Mcnemar&#39;s Test P-Value : &lt; 2e-16         
##                                           
##             Sensitivity : 0.9854          
##             Specificity : 0.1077          
##          Pos Pred Value : 0.7528          
##          Neg Pred Value : 0.7284          
##              Prevalence : 0.7339          
##          Detection Rate : 0.7232          
##    Detection Prevalence : 0.9607          
##       Balanced Accuracy : 0.5466          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<div id="area-under-the-roc-curv-auc" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Area Under the ROC Curv (AUC)</h3>
<p>What if we look at both the true-positive rate (TPR) and false positive rate (FPR) simultaneously? That is, for each value of the cutoff, we can calculate the TPR and TNR.</p>
<p>For example, say that we have 10 cutoff values, <span class="math inline">\(\{k_1, k_2, ..., k_{10}\}\)</span>. Then for each value of <span class="math inline">\(k\)</span> we calculate both the true positive rates</p>
<p><span class="math display">\[\text{TPR} = \{\text{TPR}(k_1), \text{TPR}(k_2), .., \text{TPR}(k_{10})\} \]</span></p>
<p>and the true negative rates</p>
<p><span class="math display">\[\{\text{FNR} = \{\text{FNR}(k_1), \text{FNR}(k_2), .., \text{FNR}(k_{10})\}\]</span></p>
<p>Then we set <code>x = TPR</code> and <code>y = FNR</code> and graph x against y. The plot below shows the ROC for the <code>auto_claims</code> data. The Area Under the Curv of 0.6795 is what we would get if we integrated under the curve.</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb221-1" title="1"><span class="kw">library</span>(pROC)</a>
<a class="sourceLine" id="cb221-2" title="2"><span class="kw">roc</span>(test<span class="op">$</span>target, preds, <span class="dt">plot =</span> T)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-41"></span>
<img src="05-linear-models_files/figure-html/unnamed-chunk-41-1.png" alt="AUC for auto_claim" width="672" />
<p class="caption">
Figure 10.3: AUC for auto_claim
</p>
</div>
<pre><code>## 
## Call:
## roc.default(response = test$target, predictor = preds, plot = T)
## 
## Data: preds in 1511 controls (test$target 0) &lt; 548 cases (test$target 1).
## Area under the curve: 0.7558</code></pre>
<p>If we just randomly guess, the AUC would be 0.5, which is represented by the 45-degree line. A perfect model would maximize the curve to the upper-left corner.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models-glms.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="penalized-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sdcastillo/PA-R-Study-Manual/edit/master/05-linear-models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Exam-PA-Study-Manual.pdf", "Exam-PA-Study-Manual.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
