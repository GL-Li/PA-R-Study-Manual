# Modeling

## What is machine learning

All of use are already familiar with how to learn - by learning from our mistakes.  By repeating what is successful and avoiding what results in failure, we "learn" by doing, by experience, or trial-and-error.  Some methods work well for learning, but other methods do not.  We all know that memorizing answers without understanding concepts is an ineffective method, and that doing many practice problems is better than doing only a few.  These ideas apply to how computers learn as much as they do to how humans learn.

Take the example of preparing for an actuarial exam.  We can clearly state our objective: get as many correct answers as possible! 

Imagine a table with one row per question.

```{r echo = F}
df <- tibble(Question = c("A = 2; B = 3; A + B = ?",
                    "A = 2; B = 10; A*B = ?",
                    "What is the meaning of life?"), 
       Solution = c(5,10, 42), 
       YourAnswer = c(6,10, 69)) 

df %>% select(Question) %>% 
  kableExtra::kable("html")
```


We want to correctly predict the solution to every problem.  

$$Y = \text{Problem Solution}, \hat{Y} = \text{Your Answer}$$

```{r echo = F}
df %>% kableExtra::kable("html")
```


Said another way, we are trying to minimize the error, the percentage of incorrect problems.  When $Y = \hat{Y}$, we answer the question correctly.  When $Y \neq \hat{Y}$, we answer incorrectly.

$$\text{Exam Score} = \sum{(Y = \hat{Y})}$$

```{r}
df %>% mutate(Correct = (YourAnswer == Solution)*1) %>% kableExtra::kable("html")
```

The "data" are the exam questions.  We want to learn the patterns from the data to create a "model" for answering new questions.
 
$$X = \text{Exam Questions}$$

The "training data" are the practice problems.  The SOA suggests 100 hours per hour of exam, which means that actuaries prepare hundreds of problems before the real exam.  Often we see the same problems multiple times, and can then peak by looking at the solution.  This can result in us "overfitting" our model if we are not careful.  

The more practice problems that we do, the larger the training data set, and the better the model becomes.  As we see more examples, our mental "model" improves.  When we see new problems, ones which have not appeared in the practice exams, we often have a difficult time.  Problems which we have seen before are easier, and we have more confidence in our answers.

To speed up the training time, we can "downsample" the data by skipping problems randomly.  For example, we can only do odd-numbered problems.  This insured that we still get the same proportion of each type of question while doing fewer problems.  

One way to be extra-confident in our answers to to do the problem multiple ways.  In modeling, using the averages of different models produces the best results.

If we use the wrong loss function our model will fail.  If instead of looking at "Correct Answers" when practicing, we do not bother to look at the answer but instead only look at "Number of Study Hours", the model will not perform well on the real exam.  The brain will "learn" to maximize study time, by taking longer time to relax and waste time, rather than aiming to get the correct answer.


## Statistical Definitions

The input columns are in a matrix format called $X$.  The target variable is a vector $y$.  By convenction, $n$ is the number of rows (aka observations) of $X$ and $p$ is the number of columns (aka variables).

Take an example with $p$ = 2 columns and 3 observations.  The matrix $X$ looks like

```{r echo = F}
tibble(x1 = c("x11", "x12", "x13"), x2 = c("x21", "x22", "x23")) %>% kableExtra::kable("html")
```

In matrix notation, you can say that $X$ is a matrix that has columns $x_1 = (x_{11}, x_{12}, x_{13}), x_3 = (x_{21}, x_{22}, x_{23})$

$$X = [x1,x2,x3] $$

The target is $y = (y_1, y_2, y_3)$.  Machine learning is about using $X$ to predict $y$. We call this "y-hat", or simply the prediction.

$$\hat{y} = f(X)$$

This is almost never going to happen perfectly, and so there is always an error term, $\epsilon$.  This can be made smaller, but is never exactly zero.  

$$\hat{y} + \epsilon = f(X) + \epsilon$$

In other words, $\epsilon = y - \hat{y}$.  

** Quiz:**

The accuracy of a model is a metric used in classification problems (where the outcome is descrete).  In the above example, what is the accuracy of the data set?

```{r}
#ncorrect / total = 1/3  = 33%
```

The goal is choose a model $f(.)$ which approximates $y$. The simplest way of doing this is with a linear model.  Choose four numbers $\beta = (\beta_0, \beta_1, \beta_2$ and say that $\hat{y}$ is a linear combination of $x_1, x_2$ using $\beta$ as the weights.

$$f(X) = X\beta = (\beta_0 + \beta_1 x_{11} + \beta_2 x_22, \beta_0 + \beta_2 x_{21} + \beta_3 x_32, \beta_0 + \beta_1 x_{31} + \beta_3 x_32)$$

-- bias variance decomposition
-- flexibility vs interpretability

## Linear Models

-- glms
  - assumptions
  - penalization (ridge vs. lasso)


-- training/testing data sets
-- cross validation

-- glm examples using
- ungrouped data w/gaussian log link
- ungrouped data w/gamma log link
- ungrouped data with binary /log link
- grouped data w/gausian log link...
- ungrouped data w/penalization

## Tree-based models

- Niemerg's "Forest from the trees" + 100 page ML book

